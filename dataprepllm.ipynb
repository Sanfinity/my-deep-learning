{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4832fc6-e1cc-420d-903a-15a198badf22",
   "metadata": {},
   "source": [
    "## Hi This is my data preparation worksheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a40092d1-c820-499e-9b9d-5fa2b25b84eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters:  20479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "      raw_text = f.read()\n",
    "\n",
    "print(\"Total number of characters: \", len(raw_text))\n",
    "raw_text[:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20fc1507-0c72-4b89-a991-75b829612f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1eb4f3d-0cb6-4d77-9fcb-d26b7a981786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ' ', 'I', ' ', 'am', ' ', 'just', ' ', 'trying', ' ', 'this', ' ', 'out!']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello I am just trying this out!\"\n",
    "result = re.split(r'(\\s)', text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "587379c3-e3d2-4cf6-80b7-bb1b7e7f78fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ' ', 'I', ' ', 'am', ' ', 'just', ' ', 'trying', ' ', 'this', ' ', 'out!']\n"
     ]
    }
   ],
   "source": [
    "result = re.split(r'[,.]|(\\s)', text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a87e4459-2451-42fd-9536-23b78e2772bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'I', 'am', 'just', 'trying', 'this', 'out!']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = [item for item in result if item.strip()]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1802f72c-2ca9-4f79-b821-e6a4819f3da4",
   "metadata": {},
   "source": [
    "This is a simple example of how a tokenizer works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e17a1657-352e-4d33-a80d-515c3033b7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)',raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0009239-b8dd-4391-8cd1-d5673d711367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
     ]
    }
   ],
   "source": [
    "preprocessed = [item for item in preprocessed if item.strip()]\n",
    "print(preprocessed[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4903e0db-ca31-43bf-95c8-be7d3c5443bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4690\n"
     ]
    }
   ],
   "source": [
    "print(len(preprocessed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9987ea92-1793-46fe-8d2a-aef75c0c82f6",
   "metadata": {},
   "source": [
    "Convert Tokens into Token IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0104f8e-48ba-4634-9df8-28a7ab38c54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "allwords = sorted(set(preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de85580c-43ec-4d83-baa8-72fe353a628b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1130"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(allwords)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d23f82dc-2923-4c6c-97bb-c15fbdb9bcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {token:integer for integer,token in enumerate(allwords)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dad2a8e-88e4-4ce4-a1ad-1dec97d902e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> ('!', 0)\n",
      "1 -> ('\"', 1)\n",
      "2 -> (\"'\", 2)\n",
      "3 -> ('(', 3)\n",
      "4 -> (')', 4)\n",
      "5 -> (',', 5)\n",
      "6 -> ('--', 6)\n",
      "7 -> ('.', 7)\n",
      "8 -> (':', 8)\n",
      "9 -> (';', 9)\n",
      "10 -> ('?', 10)\n",
      "11 -> ('A', 11)\n",
      "12 -> ('Ah', 12)\n",
      "13 -> ('Among', 13)\n",
      "14 -> ('And', 14)\n",
      "15 -> ('Are', 15)\n",
      "16 -> ('Arrt', 16)\n",
      "17 -> ('As', 17)\n",
      "18 -> ('At', 18)\n",
      "19 -> ('Be', 19)\n",
      "20 -> ('Begin', 20)\n"
     ]
    }
   ],
   "source": [
    "for i,item in enumerate(vocab.items()):\n",
    "    print(i,\"->\",item)\n",
    "    if i>=20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e027d15-39be-4cdc-b925-e3e9867da26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "\n",
    "    def encode(self,text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)',text)\n",
    "        preprocessed = [item for item in preprocessed if item.strip()]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        text = re.sub(r'\\s+([,.:;?_!\"()\\'])', r'\\1',text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ee48545-62b9-4c79-9636-48ae3cc74fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "text = \"\"\"\"It's the last he painted, you know,\"\n",
    "           Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46f441a5-4334-424c-a21e-bb19158d8da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0254a857-4d8f-47ca-a52d-b373eab9befe",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Hello'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m sampleText \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello, do you like tea?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampleText\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[13], line 9\u001b[0m, in \u001b[0;36mSimpleTokenizerV1.encode\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m      7\u001b[0m preprocessed \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m([,.:;?_!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m()\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m]|--|\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms)\u001b[39m\u001b[38;5;124m'\u001b[39m,text)\n\u001b[0;32m      8\u001b[0m preprocessed \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m preprocessed \u001b[38;5;28;01mif\u001b[39;00m item\u001b[38;5;241m.\u001b[39mstrip()]\n\u001b[1;32m----> 9\u001b[0m ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr_to_int\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m preprocessed]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Hello'"
     ]
    }
   ],
   "source": [
    "sampleText = \"Hello, do you like tea?\"\n",
    "print(tokenizer.encode(sampleText))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6a3c22-7270-4067-9f34-e0cf7afc225e",
   "metadata": {},
   "source": [
    "Adding Special Context tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7497e9e7-85eb-4fb8-b5cb-936b6798fd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "alltokens = sorted(set(preprocessed))\n",
    "alltokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "vocab = {token:integer for integer,token in enumerate(alltokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92172c98-2a13-441b-add1-afdc9758bbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1132"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38c85d69-bd73-4aa1-9b27-69e5310a7e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV2 :\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "\n",
    "    def encode(self,text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)',text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed [\n",
    "            item if item in self.str_to_int\n",
    "            else [ \"<|unk|>\" for item in preprocessed ]\n",
    "        ]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        text = re.sub(r'\\s+([,.:;?_!\"()\\'])', r'\\1',text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0c6a679-43d2-45bb-9a08-3cdee257c92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV2\n",
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "text = \" <|endoftext|> \".join((text1,text2))\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8df52e5-96bc-42a2-9184-4cf4318dd4c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SimpleTokenizerV2.encode() missing 1 required positional argument: 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: SimpleTokenizerV2.encode() missing 1 required positional argument: 'text'"
     ]
    }
   ],
   "source": [
    "tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d23bf34-1489-40fa-a455-58478af1b2ea",
   "metadata": {},
   "source": [
    "## Byte Pair Encoding (BPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4140a580-1936-418c-9a98-3fb504974e61",
   "metadata": {},
   "source": [
    "Used in GPT-2 and GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8df6a5b2-cd83-49bf-a2df-a82cc0041f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.9.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\san36\\appdata\\roaming\\python\\python312\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\san36\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\san36\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\san36\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\san36\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
      "Downloading tiktoken-0.9.0-cp312-cp312-win_amd64.whl (894 kB)\n",
      "   ---------------------------------------- 0.0/894.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 894.9/894.9 kB 5.8 MB/s eta 0:00:00\n",
      "Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Installing collected packages: regex, tiktoken\n",
      "Successfully installed regex-2024.11.6 tiktoken-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce05bd23-6547-4f40-a3fc-b9e57d8c4b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.9.0\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import tiktoken\n",
    "\n",
    "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bca16bd7-5c1a-42dc-9322-f532b1abc078",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b8eb68d-ce20-46eb-875d-55cb27ba858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "        \"of someunknownPlace.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e58b44f0-a08a-498c-97e3-114230b9ac5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
     ]
    }
   ],
   "source": [
    "integers = tokenizer.encode(text, allowed_special = {\"<|endoftext|>\"})\n",
    "\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab695c91-9935-43bf-89f6-6af0774eb259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " strings = tokenizer.decode(integers)\n",
    "strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee102914-1493-469e-b4fd-01a39ae8a461",
   "metadata": {},
   "source": [
    "### Create Input - Target data pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c4bc0ca-2a44-4721-9c80-b850546b47fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_text = tokenizer.encode(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b203499-0b72-490f-8dd6-22504560e4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n"
     ]
    }
   ],
   "source": [
    "print(len(enc_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759ffc8e-da22-4d29-b5c3-a8cc95406854",
   "metadata": {},
   "source": [
    "context size is the size of tokens included in the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12ee28d6-690a-4958-b258-078e8d1f74de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'enc_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m context_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m----> 3\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43menc_sample\u001b[49m[:context_size]\n\u001b[0;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m enc_sample[\u001b[38;5;241m1\u001b[39m:context_size\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'enc_sample' is not defined"
     ]
    }
   ],
   "source": [
    "context_size = 4\n",
    "\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size+1]\n",
    "\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y:      {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7126e9c2-9a2b-4361-aa3a-af5e1d73b716",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'enc_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, context_size\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43menc_sample\u001b[49m[:i]\n\u001b[0;32m      3\u001b[0m     desired \u001b[38;5;241m=\u001b[39m enc_sample[i]\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(context, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--->\u001b[39m\u001b[38;5;124m\"\u001b[39m, desired)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'enc_sample' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(context, \"--->\", desired)\n",
    "    print(tokenizer.decode(context), \"--->\", tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a8d89d-7a0f-430e-ab03-24f58fe9b24d",
   "metadata": {},
   "source": [
    "But we need these in the form of tensors as pytorch always works with tensors (i/p tensor & o/p tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b1b864-9348-48d2-b7f7-7b0773895c27",
   "metadata": {},
   "source": [
    "#### Implementing a Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a915602b-3c8e-47ec-9469-0948ec5b76bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bcbbbd6a-cd1b-488b-9f44-0f97d11c4069",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, text, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.output_ids = []\n",
    "        token_ids = tokenizer.encode(text, allowed_special = {\"<|endoftext|>\"})\n",
    "        print(f\"Total tokens: {len(token_ids)}\")\n",
    "\n",
    "        if len(token_ids) < max_length:\n",
    "            print(\"⚠️ Text is too short! Try reducing max_length.\")\n",
    "            return  \n",
    "        for i in range(0, len(token_ids)-max_length, stride):\n",
    "            input_chunk = token_ids[i:i+max_length]\n",
    "            target_chunk = token_ids[i+1:i+max_length+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.output_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.input_ids[idx], self.output_ids[idx]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92654566-5bd5-46c7-8856-d873f7dc38b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
    "                         stride=128, shuffle=True, drop_last = True,\n",
    "                         num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    print(f\"Total samples in dataset: {len(dataset)}\")\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ea3e88-8a82-4a73-9372-ea249c1771ff",
   "metadata": {},
   "source": [
    "Difference between batch_size and num_workers => batch size is the number of operations the model perform before updating its parameters, while num_workers is the parallel procession consumption of cpus/gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7650c318-f4bf-49a5-be64-425ed42e62be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "65cc4942-e490-4059-9502-b707334f7c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[15496,    11,   466,   345]]), tensor([[ 11, 466, 345, 588]])]\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batch_size=1, max_length=4, stride=1, shuffle=False)\n",
    "\n",
    "data_itr = iter(dataloader)\n",
    "first_batch = next(data_itr)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c226c286-16e5-4a72-948e-b2ed5367b1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_batch = next(data_itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d4f06e3e-b5d7-4f7c-8c0b-f447c90b662d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 11, 466, 345, 588]]), tensor([[ 466,  345,  588, 8887]])]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b4fad133-ac58-403c-9585-9c5e6bf0b778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[15496,    11,   466,   345],\n",
      "        [  588,  8887,    30,   220],\n",
      "        [50256,   554,   262,  4252],\n",
      "        [18250,  8812,  2114,  1659]]) ---> tensor([[   11,   466,   345,   588],\n",
      "        [ 8887,    30,   220, 50256],\n",
      "        [  554,   262,  4252, 18250],\n",
      "        [ 8812,  2114,  1659,   617]])\n"
     ]
    }
   ],
   "source": [
    "dataloader2 = create_dataloader_v1(raw_text, batch_size=4, max_length=4, stride=4, shuffle=False)\n",
    "\n",
    "data_itr2 = iter(dataloader2)\n",
    "inputs,targets = next(data_itr2)\n",
    "print(inputs, \"--->\", targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49889d73-6e7d-4338-87cf-694545477ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp312-cp312-win_amd64.whl.metadata (8.2 kB)\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Downloading scipy-1.13.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Downloading gensim-4.3.3-cp312-cp312-win_amd64.whl (24.0 MB)\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/24.0 MB 6.7 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 1.6/24.0 MB 3.6 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 2.1/24.0 MB 3.2 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 3.1/24.0 MB 3.9 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 4.2/24.0 MB 3.9 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 5.0/24.0 MB 3.9 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.8/24.0 MB 3.9 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 6.6/24.0 MB 3.9 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 7.3/24.0 MB 3.9 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.1/24.0 MB 3.9 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 8.9/24.0 MB 3.9 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 9.7/24.0 MB 3.9 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 10.7/24.0 MB 3.9 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 11.5/24.0 MB 3.9 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 12.3/24.0 MB 3.9 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 13.1/24.0 MB 3.9 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 13.9/24.0 MB 3.9 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 14.7/24.0 MB 3.9 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 15.5/24.0 MB 3.9 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 16.3/24.0 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.3/24.0 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 17.6/24.0 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 18.9/24.0 MB 3.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 19.7/24.0 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 20.4/24.0 MB 3.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.2/24.0 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.0/24.0 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.8/24.0 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.6/24.0 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.0/24.0 MB 3.9 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.0/15.5 MB 4.6 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.8/15.5 MB 4.2 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 2.6/15.5 MB 4.1 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 3.4/15.5 MB 4.0 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 4.2/15.5 MB 4.0 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 5.0/15.5 MB 4.0 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 5.8/15.5 MB 4.0 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 6.6/15.5 MB 3.9 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 7.3/15.5 MB 3.9 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 8.1/15.5 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 8.9/15.5 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 10.0/15.5 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 10.7/15.5 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 11.3/15.5 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 12.1/15.5 MB 3.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.8/15.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.9/15.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.7/15.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.5/15.5 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading scipy-1.13.1-cp312-cp312-win_amd64.whl (45.9 MB)\n",
      "   ---------------------------------------- 0.0/45.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.8/45.9 MB 3.7 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 1.6/45.9 MB 3.7 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 2.4/45.9 MB 3.7 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 3.1/45.9 MB 3.7 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 3.9/45.9 MB 3.7 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 4.7/45.9 MB 3.8 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 5.5/45.9 MB 3.8 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 6.3/45.9 MB 3.7 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 7.1/45.9 MB 3.8 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 7.6/45.9 MB 3.8 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 8.4/45.9 MB 3.7 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 9.2/45.9 MB 3.8 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 10.0/45.9 MB 3.8 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 11.0/45.9 MB 3.8 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 11.8/45.9 MB 3.8 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 12.6/45.9 MB 3.8 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 13.4/45.9 MB 3.8 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 14.2/45.9 MB 3.8 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 14.9/45.9 MB 3.8 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 15.7/45.9 MB 3.8 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 16.5/45.9 MB 3.8 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 17.3/45.9 MB 3.8 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 18.1/45.9 MB 3.8 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 18.9/45.9 MB 3.8 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 19.7/45.9 MB 3.8 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 20.7/45.9 MB 3.8 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 21.2/45.9 MB 3.8 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 22.3/45.9 MB 3.8 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 23.1/45.9 MB 3.8 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 23.9/45.9 MB 3.8 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 24.6/45.9 MB 3.8 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 25.4/45.9 MB 3.8 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 26.2/45.9 MB 3.8 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 27.0/45.9 MB 3.8 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 27.8/45.9 MB 3.8 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 28.6/45.9 MB 3.8 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 29.4/45.9 MB 3.8 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 30.1/45.9 MB 3.8 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 30.9/45.9 MB 3.8 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 32.0/45.9 MB 3.8 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 32.8/45.9 MB 3.8 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 33.6/45.9 MB 3.8 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 34.3/45.9 MB 3.8 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 34.9/45.9 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 35.9/45.9 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 36.7/45.9 MB 3.8 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 37.5/45.9 MB 3.8 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 38.5/45.9 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 39.3/45.9 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 40.1/45.9 MB 3.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 40.9/45.9 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 41.7/45.9 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 42.5/45.9 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 43.3/45.9 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.0/45.9 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.8/45.9 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.6/45.9 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 45.9/45.9 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Installing collected packages: wrapt, numpy, smart-open, scipy, gensim\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.1\n",
      "    Uninstalling numpy-2.1.1:\n",
      "      Successfully uninstalled numpy-2.1.1\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.15.2\n",
      "    Uninstalling scipy-1.15.2:\n",
      "      Successfully uninstalled scipy-1.15.2\n",
      "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0 wrapt-1.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e27b790-edda-40e0-abf2-582d0d0ae689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "115b6c42-354f-427a-ad3b-f2c2af39e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d48629-7e17-47be-9d4e-26ba210583b3",
   "metadata": {},
   "source": [
    "300 in this stands for 300 dim vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b38421b6-cff6-4c17-af16-114631054f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.07421875e-01 -2.01171875e-01  1.23046875e-01  2.11914062e-01\n",
      " -9.13085938e-02  2.16796875e-01 -1.31835938e-01  8.30078125e-02\n",
      "  2.02148438e-01  4.78515625e-02  3.66210938e-02 -2.45361328e-02\n",
      "  2.39257812e-02 -1.60156250e-01 -2.61230469e-02  9.71679688e-02\n",
      " -6.34765625e-02  1.84570312e-01  1.70898438e-01 -1.63085938e-01\n",
      " -1.09375000e-01  1.49414062e-01 -4.65393066e-04  9.61914062e-02\n",
      "  1.68945312e-01  2.60925293e-03  8.93554688e-02  6.49414062e-02\n",
      "  3.56445312e-02 -6.93359375e-02 -1.46484375e-01 -1.21093750e-01\n",
      " -2.27539062e-01  2.45361328e-02 -1.24511719e-01 -3.18359375e-01\n",
      " -2.20703125e-01  1.30859375e-01  3.66210938e-02 -3.63769531e-02\n",
      " -1.13281250e-01  1.95312500e-01  9.76562500e-02  1.26953125e-01\n",
      "  6.59179688e-02  6.93359375e-02  1.02539062e-02  1.75781250e-01\n",
      " -1.68945312e-01  1.21307373e-03 -2.98828125e-01 -1.15234375e-01\n",
      "  5.66406250e-02 -1.77734375e-01 -2.08984375e-01  1.76757812e-01\n",
      "  2.38037109e-02 -2.57812500e-01 -4.46777344e-02  1.88476562e-01\n",
      "  5.51757812e-02  5.02929688e-02 -1.06933594e-01  1.89453125e-01\n",
      " -1.16210938e-01  8.49609375e-02 -1.71875000e-01  2.45117188e-01\n",
      " -1.73828125e-01 -8.30078125e-03  4.56542969e-02 -1.61132812e-02\n",
      "  1.86523438e-01 -6.05468750e-02 -4.17480469e-02  1.82617188e-01\n",
      "  2.20703125e-01 -1.22558594e-01 -2.55126953e-02 -3.08593750e-01\n",
      "  9.13085938e-02  1.60156250e-01  1.70898438e-01  1.19628906e-01\n",
      "  7.08007812e-02 -2.64892578e-02 -3.08837891e-02  4.06250000e-01\n",
      " -1.01562500e-01  5.71289062e-02 -7.26318359e-03 -9.17968750e-02\n",
      " -1.50390625e-01 -2.55859375e-01  2.16796875e-01 -3.63769531e-02\n",
      "  2.24609375e-01  8.00781250e-02  1.56250000e-01  5.27343750e-02\n",
      "  1.50390625e-01 -1.14746094e-01 -8.64257812e-02  1.19140625e-01\n",
      " -7.17773438e-02  2.73437500e-01 -1.64062500e-01  7.29370117e-03\n",
      "  4.21875000e-01 -1.12792969e-01 -1.35742188e-01 -1.31835938e-01\n",
      " -1.37695312e-01 -7.66601562e-02  6.25000000e-02  4.98046875e-02\n",
      " -1.91406250e-01 -6.03027344e-02  2.27539062e-01  5.88378906e-02\n",
      " -3.24218750e-01  5.41992188e-02 -1.35742188e-01  8.17871094e-03\n",
      " -5.24902344e-02 -1.74713135e-03 -9.81445312e-02 -2.86865234e-02\n",
      "  3.61328125e-02  2.15820312e-01  5.98144531e-02 -3.08593750e-01\n",
      " -2.27539062e-01  2.61718750e-01  9.86328125e-02 -5.07812500e-02\n",
      "  1.78222656e-02  1.31835938e-01 -5.35156250e-01 -1.81640625e-01\n",
      "  1.38671875e-01 -3.10546875e-01 -9.71679688e-02  1.31835938e-01\n",
      " -1.16210938e-01  7.03125000e-02  2.85156250e-01  3.51562500e-02\n",
      " -1.01562500e-01 -3.75976562e-02  1.41601562e-01  1.42578125e-01\n",
      " -5.68847656e-02  2.65625000e-01 -2.09960938e-01  9.64355469e-03\n",
      " -6.68945312e-02 -4.83398438e-02 -6.10351562e-02  2.45117188e-01\n",
      " -9.66796875e-02  1.78222656e-02 -1.27929688e-01 -4.78515625e-02\n",
      " -7.26318359e-03  1.79687500e-01  2.78320312e-02 -2.10937500e-01\n",
      " -1.43554688e-01 -1.27929688e-01  1.73339844e-02 -3.60107422e-03\n",
      " -2.04101562e-01  3.63159180e-03 -1.19628906e-01 -6.15234375e-02\n",
      "  5.93261719e-02 -3.23486328e-03 -1.70898438e-01 -3.14941406e-02\n",
      " -8.88671875e-02 -2.89062500e-01  3.44238281e-02 -1.87500000e-01\n",
      "  2.94921875e-01  1.58203125e-01 -1.19628906e-01  7.61718750e-02\n",
      "  6.39648438e-02 -4.68750000e-02 -6.83593750e-02  1.21459961e-02\n",
      " -1.44531250e-01  4.54101562e-02  3.68652344e-02  3.88671875e-01\n",
      "  1.45507812e-01 -2.55859375e-01 -4.46777344e-02 -1.33789062e-01\n",
      " -1.38671875e-01  6.59179688e-02  1.37695312e-01  1.14746094e-01\n",
      "  2.03125000e-01 -4.78515625e-02  1.80664062e-02 -8.54492188e-02\n",
      " -2.48046875e-01 -3.39843750e-01 -2.83203125e-02  1.05468750e-01\n",
      " -2.14843750e-01 -8.74023438e-02  7.12890625e-02  1.87500000e-01\n",
      " -1.12304688e-01  2.73437500e-01 -3.26171875e-01 -1.77734375e-01\n",
      " -4.24804688e-02 -2.69531250e-01  6.64062500e-02 -6.88476562e-02\n",
      " -1.99218750e-01 -7.03125000e-02 -2.43164062e-01 -3.66210938e-02\n",
      " -7.37304688e-02 -1.77734375e-01  9.17968750e-02 -1.25000000e-01\n",
      " -1.65039062e-01 -3.57421875e-01 -2.85156250e-01 -1.66992188e-01\n",
      "  1.97265625e-01 -1.53320312e-01  2.31933594e-02  2.06054688e-01\n",
      "  1.80664062e-01 -2.74658203e-02 -1.92382812e-01 -9.61914062e-02\n",
      " -1.06811523e-02 -4.73632812e-02  6.54296875e-02 -1.25732422e-02\n",
      "  1.78222656e-02 -8.00781250e-02 -2.59765625e-01  9.37500000e-02\n",
      " -7.81250000e-02  4.68750000e-02 -2.22167969e-02  1.86767578e-02\n",
      "  3.11279297e-02  1.04980469e-02 -1.69921875e-01  2.58789062e-02\n",
      " -3.41796875e-02 -1.44042969e-02 -5.46875000e-02 -8.78906250e-02\n",
      "  1.96838379e-03  2.23632812e-01 -1.36718750e-01  1.75781250e-01\n",
      " -1.63085938e-01  1.87500000e-01  3.44238281e-02 -5.63964844e-02\n",
      " -2.27689743e-05  4.27246094e-02  5.81054688e-02 -1.07910156e-01\n",
      " -3.88183594e-02 -2.69531250e-01  3.34472656e-02  9.81445312e-02\n",
      "  5.63964844e-02  2.23632812e-01 -5.49316406e-02  1.46484375e-01\n",
      "  5.93261719e-02 -2.19726562e-01  6.39648438e-02  1.66015625e-02\n",
      "  4.56542969e-02  3.26171875e-01 -3.80859375e-01  1.70898438e-01\n",
      "  5.66406250e-02 -1.04492188e-01  1.38671875e-01 -1.57226562e-01\n",
      "  3.23486328e-03 -4.80957031e-02 -2.48046875e-01 -6.20117188e-02]\n"
     ]
    }
   ],
   "source": [
    "word_vectors = model\n",
    "print(word_vectors['computer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52dd5435-bbfb-4208-ba60-8ebb9f2375e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors['cat'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1b3fbf-53cd-413c-916f-ef35208ee0b1",
   "metadata": {},
   "source": [
    "King + Women - Man = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "273ac3f5-0de3-4a46-9c20-059218d07d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.4827326238155365), ('queens', 0.466781347990036), ('kumaris', 0.4653734564781189), ('kings', 0.4558638632297516), ('womens', 0.422832190990448), ('princes', 0.4176960587501526), ('Al_Anqari', 0.41725507378578186), ('concubines', 0.4011078476905823), ('monarch', 0.3962482810020447), ('monarchy', 0.39430150389671326)]\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors.most_similar(positive=['king', 'women'], negative=['man'], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "043819bf-bec9-4191-9e8b-9292dc05c4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('towers', 0.8531750440597534), ('skyscraper', 0.6417425870895386), ('Tower', 0.639177143573761), ('spire', 0.594687819480896), ('responded_Understood_Atlasjet', 0.5931612253189087)]\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors.most_similar(\"tower\", topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5848e3d7-dbc9-4cbb-b5f8-abf8b9dece41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76640123\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors.similarity('woman', 'man'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5aee7a6-ad2a-471c-b968-97d110cc1999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a64a7a58-0d8d-4853-a03f-a369ee5a1ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_diff = word_vectors['man'] - word_vectors['women']\n",
    "magnitude_of_difference = np.linalg.norm(vec_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3141d4c-84d1-4c12-839b-0a3f95f9dc73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9112875"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "magnitude_of_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a8a808-81b6-43df-86fe-1fb8dfe127f8",
   "metadata": {},
   "source": [
    "The closer the relation the lesser the magnitude of difference between the vectors (which is basically the distance between the vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc384589-47c8-421d-81c4-34c1db747fce",
   "metadata": {},
   "source": [
    "### Creating Token Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50f82330-dd1c-4cca-be25-396b436ded27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "input_ids = torch.tensor([2,3,5,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641dc00f-ffd0-4ca7-9a13-1171a21c51c7",
   "metadata": {},
   "source": [
    "Quick fox is in the house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed9e90cb-5db7-4839-a030-3448c8221065",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7ef9df9-adc6-47d0-a51e-c76683c85d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1660a07-152d-4df4-8742-2562beb00dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(torch.tensor([3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18ea534d-564e-49e0-a332-d62634c2a3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3da867-6e02-4f4c-bee0-5074b88d6ac7",
   "metadata": {},
   "source": [
    "So basically, Embedding layer is a simple lookup operation that retrieves rows from the embedding layer weight matrix using a Token ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06426a9-3f02-4c85-a902-b428cbdc8f0d",
   "metadata": {},
   "source": [
    "### Positional Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9630a16f-20dd-403b-ba79-5c5aea9923fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw text length: 20479\n"
     ]
    }
   ],
   "source": [
    "print(f\"Raw text length: {len(raw_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f2286de-2cb9-4563-ae83-f2f780bb0c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60c293c4-7a17-4459-a1fd-ad97ae17d0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 5145\n",
      "Total samples in dataset: 1286\n"
     ]
    }
   ],
   "source": [
    "max_lengeth = 4\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=max_lengeth, stride=max_lengeth, shuffle=False)\n",
    "data_iter = iter(dataloader)\n",
    "inputs,targets = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7177e91b-a7a3-4046-898c-ed2dffefbdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:  tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "Target IDs:  tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n",
      "Input shape:  torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token IDs: \", inputs)\n",
    "print(\"Target IDs: \", targets)\n",
    "print(\"Input shape: \", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cb9e6d6e-7f1d-44ac-9a8e-d9792654fbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ca1a34bc-1605-4ef5-ad4d-911df7e6734a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1879776b-af75-4da5-a8ba-97ef0f8df975",
   "metadata": {},
   "source": [
    "Another Embedding layer for positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fba66d92-84df-4389-bfd0-15ce3a388509",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = max_lengeth\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "83850802-ac5f-4ed6-a2e1-7ec5ba3c5b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "pos_embeddings = pos_embedding_layer(torch.arange(max_lengeth))\n",
    "print(pos_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "96291ce8-eeaf-4554-9600-98daa115ce5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0841,  0.8481, -0.2037,  ...,  1.0956,  1.4326,  0.2528],\n",
       "        [-0.6772,  0.2824,  0.9444,  ..., -2.2544, -0.8818, -0.3394],\n",
       "        [ 0.1966,  0.8533,  0.6744,  ..., -0.8597,  0.1662,  0.2231],\n",
       "        [-1.1089, -0.7789,  1.4223,  ..., -1.3181, -1.5432, -0.6921]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788fdfae-ccbb-4c25-8785-8e8624719eea",
   "metadata": {},
   "source": [
    "Input Embedding = Token Embedding + Position Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d6c38739-cf67-4f44-ad17-43133374fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c2c5f0eb-0414-4f01-acb4-b9b227558b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "print(input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ea619505-bc5b-4faf-a2af-3a5f4a378fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.4574e+00,  1.5856e+00, -8.6933e-01,  ...,  1.2545e+00,\n",
       "           1.2707e+00, -6.2303e-01],\n",
       "         [ 4.2327e-01, -1.5343e+00,  2.1609e+00,  ..., -4.0276e+00,\n",
       "          -1.9354e+00,  1.3579e+00],\n",
       "         [-6.6976e-02,  8.3938e-01,  4.8344e-01,  ..., -1.0456e+00,\n",
       "           7.8556e-01, -4.0891e-01],\n",
       "         [ 3.3837e-01, -1.2382e+00,  1.1110e+00,  ...,  2.1853e-01,\n",
       "          -2.6571e+00, -5.0091e-01]],\n",
       "\n",
       "        [[ 4.4888e-01,  1.0762e+00,  6.3291e-01,  ..., -4.2410e-01,\n",
       "           8.5268e-01,  2.9654e-01],\n",
       "         [-6.5944e-01,  6.8111e-01,  2.0689e+00,  ..., -3.7389e+00,\n",
       "          -2.0054e-01,  3.8500e-01],\n",
       "         [-8.0545e-01,  3.5989e-01,  2.0445e+00,  ...,  8.4055e-01,\n",
       "          -5.4681e-01,  9.5492e-01],\n",
       "         [-2.7666e+00, -1.1245e+00,  1.5913e+00,  ..., -2.3436e+00,\n",
       "          -4.9883e-02, -4.3736e-03]],\n",
       "\n",
       "        [[ 1.4605e-01,  3.1457e+00, -2.9976e+00,  ...,  9.1621e-01,\n",
       "           9.2723e-01,  1.8062e-01],\n",
       "         [-7.8389e-01,  1.5837e+00,  1.5828e+00,  ..., -1.7988e+00,\n",
       "          -1.6342e+00, -1.1156e+00],\n",
       "         [-4.6377e-01,  8.6621e-01,  2.8105e+00,  ..., -8.9357e-01,\n",
       "           1.1235e+00,  2.3790e+00],\n",
       "         [-4.2919e-01, -1.6866e+00,  2.5027e+00,  ...,  9.2521e-01,\n",
       "          -4.2578e-01, -1.6487e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.3186e-01,  3.3165e+00,  1.1516e+00,  ...,  4.2326e-01,\n",
       "           1.4787e+00, -9.9594e-01],\n",
       "         [ 6.6673e-01,  1.3263e-01,  2.6270e+00,  ..., -3.2932e+00,\n",
       "          -5.5446e-01, -2.0537e-01],\n",
       "         [ 1.7129e+00,  1.5612e+00, -8.1434e-01,  ..., -9.2467e-01,\n",
       "          -1.5186e+00,  1.6787e+00],\n",
       "         [-9.6014e-01,  9.5385e-01,  1.9515e+00,  ..., -1.6699e+00,\n",
       "          -1.3648e+00, -1.1531e+00]],\n",
       "\n",
       "        [[ 1.2040e+00,  2.5150e+00, -6.2038e-01,  ...,  5.2328e-01,\n",
       "           1.9539e+00, -1.8861e-01],\n",
       "         [-9.0195e-01,  1.5673e+00,  1.6540e+00,  ..., -2.0141e+00,\n",
       "          -1.1049e+00, -7.8718e-01],\n",
       "         [ 1.0139e+00,  1.4881e+00, -1.6629e-03,  ...,  1.8567e-01,\n",
       "          -4.8880e-01,  1.7313e+00],\n",
       "         [-2.5178e+00, -5.1573e-01,  2.3952e+00,  ..., -1.7490e+00,\n",
       "          -1.8586e+00,  8.5793e-01]],\n",
       "\n",
       "        [[ 1.9015e+00,  1.4829e+00, -8.7978e-01,  ...,  2.1410e+00,\n",
       "           7.7758e-01,  1.7611e+00],\n",
       "         [-6.3954e-02, -3.7382e-01,  6.7920e-01,  ..., -2.5304e+00,\n",
       "          -2.2661e+00,  9.5828e-01],\n",
       "         [ 4.3559e-02,  9.1882e-01,  1.2207e-01,  ...,  4.9827e-01,\n",
       "           8.3262e-02,  9.4379e-01],\n",
       "         [-3.4626e-01,  3.9235e-01,  3.2536e-01,  ...,  3.1035e-01,\n",
       "          -1.9813e-02, -1.8316e+00]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04855d40-1631-4be5-8698-ee428161cbbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21b121d-d33f-4fe9-bf9e-26ad3b5d5813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
